{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set current working directory to the root of the project\n",
    "## !! Run this once only once\n",
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import csv\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Any, List, Sequence, Callable\n",
    "from itertools import islice, zip_longest\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast, BertModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "import pyarrow.csv as csv\n",
    "\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = 'data/NQ320K/raw'\n",
    "output_dir = 'data/NQ320K/output'\n",
    "cache_dir = 'data/NQ320K/cache'\n",
    "pretrained_dir = 'data/pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_path = bert_model_identifier = 'bert-base-uncased'\n",
    "genq_model_identifier = 'doc2query-t5-base-msmarco-ft_NQ320K'\n",
    "genq_model_path = \"data/pretrained/doc2query-t5-base-msmarco-ft_NQ320K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Extract data into `data/NQ320K/raw`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the following links in your browser to download automatically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NQ Train: https://storage.cloud.google.com/natural_questions/v1.0-simplified/simplified-nq-train.jsonl.gz\n",
    "##### NQ Dev: https://storage.cloud.google.com/natural_questions/v1.0-simplified/nq-dev-all.jsonl.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Note:__ Please download them directly via your browser (e.g., Microsoft Edge) then place them into `data/NQ320K/raw` directory.\n",
    "#### Do not use `gsutil` or `wget` command directly on the above links to prevent file incompatibility or corruption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Extract query-document samples from raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"query\",\n",
    "    \"queryid\",\n",
    "    \"long_answer\",\n",
    "    \"short_answer\",\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "    \"content\",\n",
    "    \"doc\",\n",
    "    \"language\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_dev = []\n",
    "\n",
    "with gzip.open(f\"{raw_dir}/v1.0-simplified_nq-dev-all.jsonl.gz\", \"r+\") as f:\n",
    "    for item in tqdm(jsonlines.Reader(f)):\n",
    "        \n",
    "        arr = []\n",
    "        ## question_text\n",
    "        question_text = item['question_text']\n",
    "        arr.append(question_text)\n",
    "\n",
    "        tokens = []\n",
    "        for i in item['document_tokens']:\n",
    "            tokens.append(i['token'])\n",
    "        document_text = ' '.join(tokens)\n",
    "        \n",
    "        ## example_id\n",
    "        example_id = str(item['example_id'])\n",
    "        arr.append(example_id)\n",
    "\n",
    "        # document_text = item['document_text']\n",
    "        ## long_answer\n",
    "        annotation = item['annotations'][0]\n",
    "        has_long_answer = annotation['long_answer']['start_token'] >= 0\n",
    "\n",
    "        long_answers = [\n",
    "            a['long_answer']\n",
    "            for a in item['annotations']\n",
    "            if a['long_answer']['start_token'] >= 0 and has_long_answer\n",
    "        ]\n",
    "        if has_long_answer:\n",
    "            start_token = long_answers[0]['start_token']\n",
    "            end_token = long_answers[0]['end_token']\n",
    "            x = document_text.split(' ')\n",
    "            long_answer = ' '.join(x[start_token:end_token])\n",
    "            long_answer = re.sub('<[^<]+?>', '', long_answer).replace('\\n', '').strip()\n",
    "        arr.append(long_answer) if has_long_answer else arr.append('')\n",
    "\n",
    "        # short_answer\n",
    "        has_short_answer = annotation['short_answers'] or annotation['yes_no_answer'] != 'NONE'\n",
    "        short_answers = [\n",
    "            a['short_answers']\n",
    "            for a in item['annotations']\n",
    "            if a['short_answers'] and has_short_answer\n",
    "        ]\n",
    "        if has_short_answer and len(annotation['short_answers']) != 0:\n",
    "            sa = []\n",
    "            for i in short_answers[0]:\n",
    "                start_token_s = i['start_token']\n",
    "                end_token_s = i['end_token']\n",
    "                shorta = ' '.join(x[start_token_s:end_token_s])\n",
    "                sa.append(shorta)\n",
    "            short_answer = '|'.join(sa)\n",
    "            short_answer = re.sub('<[^<]+?>', '', short_answer).replace('\\n', '').strip()\n",
    "        arr.append(short_answer) if has_short_answer else arr.append('')\n",
    "\n",
    "        ## title\n",
    "        arr.append(item['document_title'])\n",
    "\n",
    "        ## abs\n",
    "        if document_text.find('<P>') != -1:\n",
    "            abs_start = document_text.index('<P>')\n",
    "            abs_end = document_text.index('</P>')\n",
    "            abs = document_text[abs_start+3:abs_end]\n",
    "        else:\n",
    "            abs = ''\n",
    "        arr.append(abs)\n",
    "\n",
    "        ## content\n",
    "        if document_text.rfind('</Ul>') != -1:\n",
    "            final = document_text.rindex('</Ul>')\n",
    "            document_text = document_text[:final]\n",
    "            if document_text.rfind('</Ul>') != -1:\n",
    "                final = document_text.rindex('</Ul>')\n",
    "                content = document_text[abs_end+4:final]\n",
    "                content = re.sub('<[^<]+?>', '', content).replace('\\n', '').strip()\n",
    "                content = re.sub(' +', ' ', content)\n",
    "                arr.append(content)\n",
    "            else:\n",
    "                content = document_text[abs_end+4:final]\n",
    "                content = re.sub('<[^<]+?>', '', content).replace('\\n', '').strip()\n",
    "                content = re.sub(' +', ' ', content)\n",
    "                arr.append(content)\n",
    "        else:\n",
    "            content = document_text[abs_end+4:]\n",
    "            content = re.sub('<[^<]+?>', '', content).replace('\\n', '').strip()\n",
    "            content = re.sub(' +', ' ', content)\n",
    "            arr.append(content)\n",
    "        doc_tac = item['document_title'] + abs + content\n",
    "        arr.append(doc_tac)\n",
    "        language = 'en'\n",
    "        arr.append(language)\n",
    "        nq_dev.append(arr)\n",
    "\n",
    "dev = pd.DataFrame(nq_dev, columns=columns)\n",
    "dev.to_csv(f\"{raw_dir}/dev.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_train = []\n",
    "with gzip.open(f\"{raw_dir}/v1.0-simplified_simplified-nq-train.jsonl.gz\", \"r+\") as f:\n",
    "    for item in tqdm(jsonlines.Reader(f)):\n",
    "        ## question_text\n",
    "        arr = []\n",
    "        question_text = item[\"question_text\"]\n",
    "        arr.append(question_text)\n",
    "\n",
    "        ## example_id\n",
    "        example_id = str(item[\"example_id\"])\n",
    "        arr.append(example_id)\n",
    "\n",
    "        document_text = item[\"document_text\"]\n",
    "\n",
    "        ## long_answer\n",
    "        annotation = item[\"annotations\"][0]\n",
    "        has_long_answer = annotation[\"long_answer\"][\"start_token\"] >= 0\n",
    "\n",
    "        long_answers = [\n",
    "            a[\"long_answer\"]\n",
    "            for a in item[\"annotations\"]\n",
    "            if a[\"long_answer\"][\"start_token\"] >= 0 and has_long_answer\n",
    "        ]\n",
    "        if has_long_answer:\n",
    "            start_token = long_answers[0][\"start_token\"]\n",
    "            end_token = long_answers[0][\"end_token\"]\n",
    "            x = document_text.split(\" \")\n",
    "            long_answer = \" \".join(x[start_token:end_token])\n",
    "            long_answer = re.sub(\"<[^<]+?>\", \"\", long_answer).replace(\"\\n\", \"\").strip()\n",
    "        arr.append(long_answer) if has_long_answer else arr.append(\"\")\n",
    "\n",
    "        # short_answer\n",
    "        has_short_answer = (\n",
    "            annotation[\"short_answers\"] or annotation[\"yes_no_answer\"] != \"NONE\"\n",
    "        )\n",
    "        short_answers = [\n",
    "            a[\"short_answers\"]\n",
    "            for a in item[\"annotations\"]\n",
    "            if a[\"short_answers\"] and has_short_answer\n",
    "        ]\n",
    "        if has_short_answer and len(annotation[\"short_answers\"]) != 0:\n",
    "            sa = []\n",
    "            for i in short_answers[0]:\n",
    "                start_token_s = i[\"start_token\"]\n",
    "                end_token_s = i[\"end_token\"]\n",
    "                shorta = \" \".join(x[start_token_s:end_token_s])\n",
    "                sa.append(shorta)\n",
    "            short_answer = \"|\".join(sa)\n",
    "            short_answer = (\n",
    "                re.sub(\"<[^<]+?>\", \"\", short_answer).replace(\"\\n\", \"\").strip()\n",
    "            )\n",
    "        arr.append(short_answer) if has_short_answer else arr.append(\"\")\n",
    "\n",
    "        ## title\n",
    "        if document_text.find(\"<H1>\") != -1:\n",
    "            title_start = document_text.index(\"<H1>\")\n",
    "            title_end = document_text.index(\"</H1>\")\n",
    "            title = document_text[title_start + 4 : title_end]\n",
    "        else:\n",
    "            title = \"\"\n",
    "        arr.append(title)\n",
    "\n",
    "        ## abs\n",
    "        if document_text.find(\"<P>\") != -1:\n",
    "            abs_start = document_text.index(\"<P>\")\n",
    "            abs_end = document_text.index(\"</P>\")\n",
    "            abs = document_text[abs_start + 3 : abs_end]\n",
    "        else:\n",
    "            abs = \"\"\n",
    "        arr.append(abs)\n",
    "\n",
    "        ## content\n",
    "        if document_text.rfind(\"</Ul>\") != -1:\n",
    "            final = document_text.rindex(\"</Ul>\")\n",
    "            document_text = document_text[:final]\n",
    "            if document_text.rfind(\"</Ul>\") != -1:\n",
    "                final = document_text.rindex(\"</Ul>\")\n",
    "                content = document_text[abs_end + 4 : final]\n",
    "                content = re.sub(\"<[^<]+?>\", \"\", content).replace(\"\\n\", \"\").strip()\n",
    "                content = re.sub(\" +\", \" \", content)\n",
    "                arr.append(content)\n",
    "            else:\n",
    "                content = document_text[abs_end + 4 : final]\n",
    "                content = re.sub(\"<[^<]+?>\", \"\", content).replace(\"\\n\", \"\").strip()\n",
    "                content = re.sub(\" +\", \" \", content)\n",
    "                arr.append(content)\n",
    "        else:\n",
    "            content = document_text[abs_end + 4 :]\n",
    "            content = re.sub(\"<[^<]+?>\", \"\", content).replace(\"\\n\", \"\").strip()\n",
    "            content = re.sub(\" +\", \" \", content)\n",
    "            arr.append(content)\n",
    "\n",
    "        doc_tac = title + abs + content\n",
    "        arr.append(doc_tac)\n",
    "\n",
    "        language = \"en\"\n",
    "        arr.append(language)\n",
    "        nq_train.append(arr)\n",
    "\n",
    "train = pd.DataFrame(nq_train, columns=columns)\n",
    "train.to_csv(f\"{raw_dir}/train.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Load extracted samples and collect unique documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read large csv files (use pyarrow to accelerate)\n",
    "def load_dev():\n",
    "    dev = csv.read_csv(\n",
    "        f'{raw_dir}/dev.tsv',\n",
    "        read_options=csv.ReadOptions(block_size=2**25),\n",
    "        parse_options=csv.ParseOptions(invalid_row_handler=lambda invalidrow:\"skip\", delimiter=\"\\t\")\n",
    "    ).to_pandas()\n",
    "    dev['title'] = dev['title'].map(lower)\n",
    "    print('dev.shape:', dev.shape)\n",
    "    return dev\n",
    "\n",
    "def load_train():\n",
    "    train = csv.read_csv(\n",
    "        f'{raw_dir}/train.tsv',\n",
    "        read_options=csv.ReadOptions(block_size=2**25),\n",
    "        parse_options=csv.ParseOptions(invalid_row_handler=lambda invalidrow:\"skip\", delimiter=\"\\t\")\n",
    "    ).to_pandas()\n",
    "    train['title'] = train['title'].map(lower)\n",
    "    print('train.shape:', train.shape)\n",
    "    return train\n",
    "\n",
    "## Clean data\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "def lower(x):\n",
    "    text = tokenizer.tokenize(x)\n",
    "    id_ = tokenizer.convert_tokens_to_ids(text)\n",
    "    return tokenizer.decode(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_train()\n",
    "dev = load_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concat train doc and validation doc to obtain full document collection\n",
    "full = pd.concat([train, dev], axis=0)\n",
    "full.reset_index(inplace = True)\n",
    "\n",
    "## Remove duplicated documents based on titles\n",
    "docs = full.drop_duplicates('title')[['title', 'abstract', 'doc']]\n",
    "docs.reset_index(inplace=True, drop=True)\n",
    "docs.index.name = \"docid\"\n",
    "\n",
    "docs.fillna({\"title\": \"\"}, inplace=True)\n",
    "assert not pd.isnull(docs['title']).any()\n",
    "\n",
    "# del full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(docs['title'] == 'nan').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The total amount of documents : 109739\n",
    "assert len(docs) == 109739\n",
    "\n",
    "## Statistics\n",
    "print(f\"# all unique documents: {len(docs)}\")\n",
    "print(\"----------- training set --------------\")\n",
    "print(f\"# Queries: {len(train)}\")\n",
    "print(f\"# Documents mentioned in training set: {len(train['title'].unique())}\")\n",
    "\n",
    "print(\"----------- dev set --------------\")\n",
    "print(f\"# Queries: {len(dev)}\")\n",
    "print(f\"# Documents mentioned dev set: {len(dev['title'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs.tsv\n",
    "docs.to_csv(f\"{raw_dir}/docs.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 {raw_dir}/docs.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Finetuning the document-to-query model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Download docT5query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "identifier = \"castorini/doc2query-t5-base-msmarco\"\n",
    "model = transformers.T5ForConditionalGeneration.from_pretrained(identifier)\n",
    "tokenizer = transformers.T5TokenizerFast.from_pretrained(identifier)\n",
    "\n",
    "os.makedirs(pretrained_dir, exist_ok=True)\n",
    "model.save_pretrained(f\"{pretrained_dir}/doc2query-t5-base-msmarco\")\n",
    "tokenizer.save_pretrained(f\"{pretrained_dir}/doc2query-t5-base-msmarco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning docT5query model with `train.doc_query.tsv` \\\n",
    "by executing the following bash command in your terminal.\n",
    "\n",
    "```bash\n",
    "    nohup python -m preprocess.finetune_t5 \\\n",
    "        --raw_ckpt data/pretrained/doc2query-t5-base-msmarco \\\n",
    "        --finetuned_ckpt data/pretrained/doc2query-t5-base-msmarco-ft_NQ320K \\\n",
    "        --train_data_path data/NQ320K/raw/train.doc_query.tsv \\\n",
    "        --val_data_path data/NQ320K/raw/dev.doc_query.tsv \\\n",
    "        --epochs 10 \\\n",
    "        --lr 5e-5 \\\n",
    "        --weight_decay 1e-2 \\\n",
    "        --batch_size 8 \\\n",
    "        --doc_max_len 512 \\\n",
    "        --query_max_len 64 \\\n",
    "        --test1000 0 \\\n",
    "        --num_nodes 1 \\\n",
    "    > log.finetuning_doc2query.log 2>&1 &\n",
    "```\n",
    "\n",
    "It takes approximately `five hours` on four RTX4090 GPUs. \\\n",
    "After the finetuning is done, the finetuned model will be saved to\n",
    "```\n",
    "    data/pretrained/doc2query-t5-base-msmarco-ft_NQ320K\n",
    "```\n",
    "\n",
    "You can optionally check the finetuning progress by executing in your terminal:\n",
    "```bash\n",
    "    tail -f log.finetuning_doc2query.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Generate queries with the finetuned document-to-query model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate queries for every document in `docs.tsv` and save them as `genq.tsv`, \\\n",
    "in which every line contains a document id and a generated query.\n",
    "\n",
    "It takes around 40 minutes on four RTX4090 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess.genq\n",
    "args = Namespace(\n",
    "    model_path=genq_model_path,\n",
    "    docs_path=f\"{raw_dir}/docs.tsv\",\n",
    "    output_path=f\"{cache_dir}/{genq_model_identifier}/genq.tsv\",\n",
    "    doc_max_len=512,\n",
    "    query_max_len=32,\n",
    "    genq_per_doc=15,\n",
    "    n_gpus=4,\n",
    "    batch_size=16,\n",
    ")\n",
    "preprocess.genq.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 {cache_dir}/{genq_model_identifier}/genq.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hierarchical K-means Indexing (HKmI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Produce for every document a BERT embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode every document in `docs.tsv` as a vector. The embeddings will be saved as `doc_emb.h5`.\n",
    "\n",
    "The encoding process will take approximately 6 minutes on four RTX4090 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess.bert_embedding\n",
    "args = Namespace(\n",
    "    docs_path=f\"{raw_dir}/docs.tsv\",\n",
    "    output_path=f\"{cache_dir}/{bert_model_identifier}/doc_emb.h5\",\n",
    "    model_path=bert_model_path,\n",
    "    max_len=512,\n",
    "    n_gpus=4,\n",
    "    text_col=\"doc\",\n",
    ")\n",
    "preprocess.bert_embedding.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Apply K-means clustering on documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying hierarchical K-means on document embeddings.\n",
    "\n",
    "Every document will be assigned an ID string, which will be saved as `docid2index.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess.kmeans\n",
    "args = Namespace(\n",
    "    embedding_path=f\"{cache_dir}/{bert_model_identifier}/doc_emb.h5\",\n",
    "    output_path=f\"{cache_dir}/{bert_model_identifier}/docid2index.HKmI.tsv\",\n",
    "    v_dim=768,\n",
    "    k=30,\n",
    "    c=30,\n",
    "    seed=7,\n",
    "    n_init=1,   # can be increased to 10/100 to enhance quality at the cost of running time\n",
    "    tol=1e-6,\n",
    ")\n",
    "preprocess.kmeans.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Use document segments as queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every document, we random select 10~12 segments of 64 tokens as queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seg(tokens):\n",
    "    begin = random.randrange(0, max(1, len(tokens) - 64))\n",
    "    end = begin + 64\n",
    "    seg = ' '.join(tokens[begin: end])\n",
    "    return seg\n",
    "\n",
    "docs = pd.read_csv(f\"{raw_dir}/docs.tsv\", sep=\"\\t\", index_col=0, na_filter=False)\n",
    "\n",
    "with open(f\"{cache_dir}/docseg.tsv\", \"wt\") as f:\n",
    "    f.write(\"docid\\tquery\\n\")\n",
    "\n",
    "    for docid, doc in docs[\"doc\"].items():\n",
    "        tokens = doc.split(\" \")\n",
    "        nsegs = 10 + max(0, len(tokens)-3000) // 3000\n",
    "        for _ in range(nsegs):\n",
    "            seg = get_seg(tokens)\n",
    "            f.write(f\"{docid}\\t{seg}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Compiling training data for training retrieval model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training set\n",
    "\n",
    "A training sample should have three entries: *query, index, docid*\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| realq_train.tsv | real queries (ground truth) |\n",
    "| genq.tsv  | generated queries from documents |\n",
    "| title_abs.tsv | concatenation of document title and abstract as query |\n",
    "| docseg.tsv | document segments as queries |\n",
    "\n",
    "- dev (evaluation) set\n",
    "\n",
    "A validation sample should have two entries: *query, docid*\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| realq_dev.tsv | real queries (ground truth) |\n",
    "\n",
    "- supporting files\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| docid2index.tsv | mapping from docid to index, used for evaluation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BMI.io\n",
    "from BMI.io import (\n",
    "    StringIndexing,\n",
    "    DocumentRetrievalTrainingFile,\n",
    "    DocumentRetrievalInferenceFile,\n",
    "    intarray_to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hkmi_dirname = f\"HKmI.{bert_model_identifier}.{genq_model_identifier}\"\n",
    "os.makedirs(f\"{output_dir}/{hkmi_dirname}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(f\"{raw_dir}/docs.tsv\", sep=\"\\t\", index_col=0, na_filter=False)\n",
    "title2docid = dict(zip(docs[\"title\"], docs.index))\n",
    "docid2index = StringIndexing.from_tsv(f\"{cache_dir}/{bert_model_identifier}/docid2index.HKmI.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docid2index.tsv\n",
    "docid2index.to_tsv(f\"{output_dir}/{hkmi_dirname}/docid2index.tsv\")\n",
    "docid2index.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realq_train.tsv\n",
    "if 'train' not in globals():\n",
    "    train = pd.read_csv(f\"{raw_dir}/train.tsv\", usecols=[\"title\", \"query\"], sep=\"\\t\")\n",
    "docids = train['title'].apply(title2docid.get)\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=train[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{hkmi_dirname}/realq_train.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realq_dev.tsv\n",
    "if 'dev' not in globals():\n",
    "    dev = pd.read_csv(f\"{raw_dir}/dev.tsv\", usecols=[\"title\", \"query\"], sep=\"\\t\")\n",
    "docids = dev['title'].apply(title2docid.get)\n",
    "\n",
    "file = DocumentRetrievalInferenceFile(\n",
    "    queries=dev[\"query\"],\n",
    "    docids=docids,\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{hkmi_dirname}/realq_dev.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_abs.tsv\n",
    "title_abs = docs[\"title\"].fillna(\"\") + \" \" + docs[\"abstract\"].fillna(\"\")\n",
    "docids = docs[\"title\"].apply(title2docid.get)\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=title_abs,\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{hkmi_dirname}/title_abs.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genq.tsv\n",
    "genq = pd.read_csv(f\"{cache_dir}/{genq_model_identifier}/genq.tsv\", usecols=[\"docid\", \"query\"], sep=\"\\t\")\n",
    "docids = genq[\"docid\"]\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=genq[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{hkmi_dirname}/genq.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docseg.tsv\n",
    "docseg = pd.read_csv(f\"{cache_dir}/docseg.tsv\", usecols=[\"docid\", \"query\"], sep=\"\\t\")\n",
    "docids = docseg[\"docid\"]\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=docseg[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{hkmi_dirname}/docseg.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bottleneck-Minimal Indexing (BMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Produce for every query a BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess.bert_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 RealQ: real queries (training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    docs_path=f\"{output_dir}/{hkmi_dirname}/realq_train.tsv\",\n",
    "    output_path=f\"{cache_dir}/{bert_model_identifier}/realq_train_emb.h5\",\n",
    "    model_path=bert_model_path,\n",
    "    max_len=512,\n",
    "    n_gpus=4,\n",
    "    text_col=\"query\",\n",
    ")\n",
    "preprocess.bert_embedding.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 GenQ: generated queries by the finetuned document-to-query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    docs_path=f\"{cache_dir}/{genq_model_identifier}/genq.tsv\",\n",
    "    output_path=f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/genq_emb.h5\",\n",
    "    model_path=bert_model_path,\n",
    "    max_len=512,\n",
    "    n_gpus=4,\n",
    "    text_col=\"query\",\n",
    ")\n",
    "preprocess.bert_embedding.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 DocSeg: using document segments as queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    docs_path=f\"{output_dir}/{hkmi_dirname}/docseg.tsv\",\n",
    "    output_path=f\"{cache_dir}/{bert_model_identifier}/docseg_emb.h5\",\n",
    "    model_path=bert_model_path,\n",
    "    max_len=512,\n",
    "    n_gpus=4,\n",
    "    text_col=\"query\",\n",
    ")\n",
    "preprocess.bert_embedding.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Apply K-means clustering on documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Calculate centroid vector for every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, ids = [], []\n",
    "for path in [\n",
    "    f\"{cache_dir}/{bert_model_identifier}/realq_train_emb.h5\",\n",
    "    f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/genq_emb.h5\",\n",
    "    f\"{cache_dir}/{bert_model_identifier}/docseg_emb.h5\",\n",
    "]:\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        X.append(f[\"embs\"][:])\n",
    "        ids.append(f[\"ids\"][:])\n",
    "X = np.concatenate(X, axis=0)\n",
    "ids = np.concatenate(ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = pd.DataFrame({'emb': list(X), 'docid': ids})\n",
    "centroids = embs.groupby(\"docid\").apply(lambda slice: np.stack(slice['emb'].values).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/doc_emb.centroid.realq_genq_docseg.h5\"\n",
    "with h5py.File(path, 'w') as f:\n",
    "    f['embs'] = np.stack(centroids.values, dtype=np.float32)\n",
    "    f['ids'] = centroids.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Run k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess.kmeans\n",
    "import importlib\n",
    "importlib.reload(preprocess.kmeans)\n",
    "\n",
    "args = Namespace(\n",
    "    embedding_path=f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/doc_emb.centroid.realq_genq_docseg.h5\",\n",
    "    output_path=f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/docid2index.BMI.realq_genq_docseg.tsv\",\n",
    "    v_dim=768,\n",
    "    k=30,\n",
    "    c=30,\n",
    "    seed=7,\n",
    "    n_init=1,   # can be increased to 10/100 to enhance quality at the cost of running time\n",
    "    tol=1e-6,\n",
    ")\n",
    "preprocess.kmeans.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compiling training data for training retrieval model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training set\n",
    "\n",
    "A training sample should have three entries: *query, index, docid*\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| realq_train.tsv | real queries (ground truth) |\n",
    "| genq.tsv  | generated queries from documents |\n",
    "| title_abs.tsv | concatenation of document title and abstract as query |\n",
    "| docseg.tsv | document segments as queries |\n",
    "\n",
    "- dev (evaluation) set\n",
    "\n",
    "A validation sample should have two entries: *query, docid*\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| realq_dev.tsv | real queries (ground truth) |\n",
    "\n",
    "- supporting files\n",
    "\n",
    "| File Name | Description |\n",
    "| --- | --- |\n",
    "| docid2index.tsv | mapping from docid to index, used for evaluation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BMI.io\n",
    "from BMI.io import (\n",
    "    StringIndexing,\n",
    "    DocumentRetrievalTrainingFile,\n",
    "    DocumentRetrievalInferenceFile,\n",
    "    intarray_to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_dirname = f\"BMI.{bert_model_identifier}.{genq_model_identifier}.realq_genq_docseg\"\n",
    "os.makedirs(f\"{output_dir}/{bmi_dirname}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(f\"{raw_dir}/docs.tsv\", sep=\"\\t\", index_col=0, na_filter=False)\n",
    "title2docid = dict(zip(docs[\"title\"], docs.index))\n",
    "docid2index = StringIndexing.from_tsv(f\"{cache_dir}/{genq_model_identifier}.{bert_model_identifier}/docid2index.BMI.realq_genq_docseg.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docid2index.tsv\n",
    "docid2index.to_tsv(f\"{output_dir}/{bmi_dirname}/docid2index.tsv\")\n",
    "docid2index.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realq_train.tsv\n",
    "if 'train' not in globals():\n",
    "    train = load_train()\n",
    "docids = train['title'].apply(title2docid.get)\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=train[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{bmi_dirname}/realq_train.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realq_dev.tsv\n",
    "if 'dev' not in globals():\n",
    "    dev = load_dev()\n",
    "docids = dev['title'].apply(title2docid.get)\n",
    "\n",
    "file = DocumentRetrievalInferenceFile(\n",
    "    queries=dev[\"query\"],\n",
    "    docids=docids,\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{bmi_dirname}/realq_dev.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_abs.tsv\n",
    "title_abs = docs[\"title\"].fillna(\"\") + \" \" + docs[\"abstract\"].fillna(\"\")\n",
    "docids = docs[\"title\"].apply(title2docid.get)\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=title_abs,\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{bmi_dirname}/title_abs.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genq.tsv\n",
    "genq = pd.read_csv(f\"{cache_dir}/{genq_model_identifier}/genq.tsv\", usecols=[\"docid\", \"query\"], sep=\"\\t\")\n",
    "docids = genq[\"docid\"]\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=genq[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{bmi_dirname}/genq.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docseg.tsv\n",
    "docseg = pd.read_csv(f\"{cache_dir}/docseg.tsv\", usecols=[\"docid\", \"query\"], sep=\"\\t\")\n",
    "docids = docseg[\"docid\"]\n",
    "indexes = docids.apply(docid2index.get_index)\n",
    "\n",
    "file = DocumentRetrievalTrainingFile(\n",
    "    queries=docseg[\"query\"],\n",
    "    docids=docids,\n",
    "    indexes=indexes.apply(intarray_to_string),\n",
    ")\n",
    "file.to_tsv(f\"{output_dir}/{bmi_dirname}/docseg.tsv\")\n",
    "file.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
